{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "Eng Ngm M2M 100",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10465607,
          "sourceType": "datasetVersion",
          "datasetId": 6479561
        }
      ],
      "dockerImageVersionId": 30839,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pri2k/ML-Practice-Repositories/blob/main/English%20Nagamese%20Language%20Translation/Eng_Ngm_M2M_100.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "_2RZqmrQshwb"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "belovedorange_english_nagamese_raw_data_path = kagglehub.dataset_download('belovedorange/english-nagamese-raw-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "1xAQmmHishwf"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylz69RupOWVK",
        "outputId": "15d72e2a-737d-426e-9799-d0ba2f4b789e",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-20T12:26:36.341474Z",
          "iopub.execute_input": "2025-01-20T12:26:36.341807Z",
          "iopub.status.idle": "2025-01-20T12:26:39.621111Z",
          "shell.execute_reply.started": "2025-01-20T12:26:36.341778Z",
          "shell.execute_reply": "2025-01-20T12:26:39.620239Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv(\"/kaggle/input/english-nagamese-raw-data/raw_data.csv\")\n",
        "\n",
        "# Verify the data\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZYkjYHAkXfT",
        "outputId": "de80a1a6-1aec-4448-c917-0bebe5532c53",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-20T12:26:39.622251Z",
          "iopub.execute_input": "2025-01-20T12:26:39.622473Z",
          "iopub.status.idle": "2025-01-20T12:26:39.690946Z",
          "shell.execute_reply.started": "2025-01-20T12:26:39.622453Z",
          "shell.execute_reply": "2025-01-20T12:26:39.69015Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                                             English  \\\n0  Paul, Silvanus, and Timothy to the church of t...   \n1  We always give thanks to God for all of you as...   \n2  We remember before our God and Father your wor...   \n3  Brothers loved by God, we know he has chosen you,   \n4  because our gospel came to you not in word onl...   \n\n                                            Nagamese  \n0  Paul aru Silvanus aru Timothy pora Isor aru Pr...  \n1  Amikhan hodai apnikhan nimite Isor ke dhanyaba...  \n2  Amikhan pora apni khan laga biswas laga kaam, ...  \n3  Isor pora morom kora bhai khan, amikhan jane T...  \n4  kilemane Isor laga kotha apni khan logote khal...  \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# data=data[:100]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-20T12:26:39.692843Z",
          "iopub.execute_input": "2025-01-20T12:26:39.693121Z",
          "iopub.status.idle": "2025-01-20T12:26:39.696848Z",
          "shell.execute_reply.started": "2025-01-20T12:26:39.693099Z",
          "shell.execute_reply": "2025-01-20T12:26:39.69594Z"
        },
        "id": "3iaPIpeGshwh"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "# Load model and tokenizer\n",
        "model_name = \"facebook/m2m100_418M\"\n",
        "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "9B9A75iDN7fu",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-20T12:26:39.697798Z",
          "iopub.execute_input": "2025-01-20T12:26:39.698019Z",
          "iopub.status.idle": "2025-01-20T12:26:41.299987Z",
          "shell.execute_reply.started": "2025-01-20T12:26:39.697998Z",
          "shell.execute_reply": "2025-01-20T12:26:41.298838Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataset\n",
        "source_texts = list(data['English'])\n",
        "target_texts = list(data['Nagamese'])\n",
        "\n",
        "# Tokenize the data\n",
        "inputs = tokenizer(source_texts, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\")\n",
        "labels = tokenizer(target_texts, return_tensors=\"pt\", max_length=128, truncation=True, padding=\"max_length\")[\"input_ids\"]\n",
        "\n",
        "# Adjust labels for loss calculation\n",
        "labels[labels == tokenizer.pad_token_id] = -100\n",
        "\n",
        "# Create DataLoader\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "dataset = TensorDataset(inputs[\"input_ids\"], inputs[\"attention_mask\"], labels)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Fine-tuning loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QDZkEoFKOTtq",
        "outputId": "9426e487-c607-484e-f1ca-cf59319fab8a",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-20T12:26:41.301186Z",
          "iopub.execute_input": "2025-01-20T12:26:41.301442Z",
          "iopub.status.idle": "2025-01-20T12:26:42.014468Z",
          "shell.execute_reply.started": "2025-01-20T12:26:41.301419Z",
          "shell.execute_reply": "2025-01-20T12:26:42.013589Z"
        }
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "M2M100ForConditionalGeneration(\n  (model): M2M100Model(\n    (shared): M2M100ScaledWordEmbedding(128112, 1024, padding_idx=1)\n    (encoder): M2M100Encoder(\n      (embed_tokens): M2M100ScaledWordEmbedding(128112, 1024, padding_idx=1)\n      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-11): 12 x M2M100EncoderLayer(\n          (self_attn): M2M100SdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): ReLU()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): M2M100Decoder(\n      (embed_tokens): M2M100ScaledWordEmbedding(128112, 1024, padding_idx=1)\n      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n      (layers): ModuleList(\n        (0-11): 12 x M2M100DecoderLayer(\n          (self_attn): M2M100SdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): ReLU()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): M2M100SdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=128112, bias=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    i = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        print(\"iterating \", i)\n",
        "        i = i+1\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save_pretrained(\"./m2m100-finetuned-english-nagamese\")\n",
        "tokenizer.save_pretrained(\"./m2m100-finetuned-english-nagamese\")"
      ],
      "metadata": {
        "id": "tzCZXYznOUcm",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-20T12:26:42.015383Z",
          "iopub.execute_input": "2025-01-20T12:26:42.015696Z",
          "iopub.status.idle": "2025-01-20T12:27:07.392258Z",
          "shell.execute_reply.started": "2025-01-20T12:26:42.015665Z",
          "shell.execute_reply": "2025-01-20T12:27:07.391297Z"
        },
        "outputId": "97e55d23-db27-4c91-959e-b7c28c4f9568"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "iterating  0\niterating  1\niterating  2\niterating  3\niterating  4\niterating  5\niterating  6\nEpoch 1, Loss: 5.061554431915283\niterating  0\niterating  1\niterating  2\niterating  3\niterating  4\niterating  5\niterating  6\nEpoch 2, Loss: 3.959017515182495\niterating  0\niterating  1\niterating  2\niterating  3\niterating  4\niterating  5\niterating  6\nEpoch 3, Loss: 3.9644460678100586\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "('./m2m100-finetuned-english-nagamese/tokenizer_config.json',\n './m2m100-finetuned-english-nagamese/special_tokens_map.json',\n 'm2m100-finetuned-english-nagamese/vocab.json',\n 'm2m100-finetuned-english-nagamese/sentencepiece.bpe.model',\n './m2m100-finetuned-english-nagamese/added_tokens.json')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "NkgkQZcdshwj"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}